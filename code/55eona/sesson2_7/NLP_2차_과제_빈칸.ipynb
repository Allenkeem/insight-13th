{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "s5BK0Ab4F_28",
      "metadata": {
        "id": "s5BK0Ab4F_28"
      },
      "source": [
        "# 1. NLP 이론문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XbPvxoevT-wC",
      "metadata": {
        "id": "XbPvxoevT-wC"
      },
      "source": [
        "## 문제 1\n",
        "일반 attention에 반해 self attention가 지닌 특징을 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tns2mhzVUM6t",
      "metadata": {
        "id": "Tns2mhzVUM6t"
      },
      "source": [
        "답 : attention과 달리 self attention는 시퀀스 속 단어들이 한번씩 쿼리 역할을 한다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kaAY-zLvUVHF",
      "metadata": {
        "id": "kaAY-zLvUVHF"
      },
      "source": [
        "## 문제 2\n",
        "BERT에 대한 설명이 아닌 것은?\n",
        "\n",
        "a) 사전 학습 모델\n",
        "\n",
        "b) 양방향 문맥 이해\n",
        "\n",
        "c) 트랜스포머의 디코더를 쌓아 올린 구조\n",
        "\n",
        "d) 이후 RoBERTa와 ALBERT로 발전"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9kPuYF2UOpO",
      "metadata": {
        "id": "N9kPuYF2UOpO"
      },
      "source": [
        "답 : c"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9mHJHJVT-nA",
      "metadata": {
        "id": "c9mHJHJVT-nA"
      },
      "source": [
        "## 문제 3\n",
        "BERT와 GPT의 학습 방식 차이를 간단히 설명하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0FsqYppaUO-6",
      "metadata": {
        "id": "0FsqYppaUO-6"
      },
      "source": [
        "답 : BERT는 매번 새로운 데이터로 학습해야하는 파인 튜닝 방법으로 학습하지만, GPT는 few-short learning을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gpQU3DA-T-eR",
      "metadata": {
        "id": "gpQU3DA-T-eR"
      },
      "source": [
        "## 문제 4\n",
        "LLM이 지닌 한계와 Rag의 필요성에 대해 간단히 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kYc85pSaT-a5",
      "metadata": {
        "id": "kYc85pSaT-a5"
      },
      "source": [
        "답 : 정확하지 않은 정보를 전달하는 할루시네이션과 많은 업데이트 비용이 필요한 LLM과 달리 Rag는 검색된 문서를 기반으로 답변을 하기 때문에 LLM의 한계를 극복할 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OsVU927lLs2Z",
      "metadata": {
        "id": "OsVU927lLs2Z"
      },
      "source": [
        "# 1. BERT 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AMZ40xeWMFIu",
      "metadata": {
        "id": "AMZ40xeWMFIu"
      },
      "source": [
        "**BERT (Bidirectional Encoder Representations from Transformers)**\n",
        "- 문장 분류(스팸 메일 탐지), 질의응답 시스템(챗봇, 검색 엔진), 번역(다국어 지원), 텍스트 요약(뉴스 요약) 등 다양한 NLP 작업에 사용\n",
        "- 문맥을 양방향으로 이해하여 텍스트의 의미를 정밀하게 파악하며, 사전 학습된 모델을 기반으로 빠르게 응용 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "inLp1BtKM_e7",
      "metadata": {
        "id": "inLp1BtKM_e7"
      },
      "source": [
        "### 1. 모델과 tokenizer 초기화\n",
        "- tokenizer를 통해 문장을 토큰으로 나누고, 이를 정수 인덱스로 변환하여 모델이 이해할 수 있도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r1m1YLY3GNM0",
      "metadata": {
        "id": "r1m1YLY3GNM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d476299-0a02-49e5-9a4b-2c640ea0dd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 tokenizer 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "# tokenizer : raw text를 개별 토큰으로 분리(Wordpiece). 토크나이저 사전에 따라 고유한 정수 인덱스(고정값)를 매핑함.\n",
        "\n",
        "# tokenizer를 통해 생성된 정수 인덱스 : 텍스트를 모델이 읽을 수 있도록 숫자화\n",
        "# Embedding vector : 단어의 의미적, 문맥적 특성을 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UJ4zRzObNqAd",
      "metadata": {
        "id": "UJ4zRzObNqAd"
      },
      "source": [
        "### 2. 입력 텍스트 준비 및 토큰화\n",
        "- [MASK] 토큰을 삽입한 문장을 설정하고, tokenizer.tokenize()로 텍스트 토큰화\n",
        "- [MASK]를 활용하여 문맥 속에서 특정 단어를 추론하는 상황을 만들고, 이를 모델이 학습한 패턴과 비교하도록 함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JKUXDaU1GRwy",
      "metadata": {
        "id": "JKUXDaU1GRwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904d7548-d7b1-470b-fa5c-21f91ba80094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '[MASK]', '을', '했', '##다', '.', '[SEP]']\n",
            "[2, 1432, 2173, 3542, 16, 3616, 2259, 4084, 2079, 3934, 2069, 3790, 6895, 2062, 18, 3673, 10514, 3657, 16, 8983, 4, 1498, 1902, 2062, 18, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트할 문장\n",
        "text = \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "\n",
        "# 문장을 토큰으로 변환\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "print(tokenized_text)\n",
        "print(indexed_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nrWA_XEN4I3",
      "metadata": {
        "id": "_nrWA_XEN4I3"
      },
      "source": [
        "### 3. MASK된 위치 확인\n",
        "- [MASK] 토큰의 위치를 탐지해 해당 위치에서 모델이 단어를 예측하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tAOGhKOrKrRC",
      "metadata": {
        "id": "tAOGhKOrKrRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2249f2c2-580c-4c68-e9bc-308fdd815632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "# 마스킹된 위치 찾기\n",
        "masked_index = tokenized_text.index(\"[MASK]\") ; print(masked_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T3oqIAqDOEo_",
      "metadata": {
        "id": "T3oqIAqDOEo_"
      },
      "source": [
        "### 4. 정수화된 토큰 인덱스를 tensor로 변환 후 모델 예측 실행\n",
        "- 모델은 텐서 데이터 구조를 필요로 하므로, 입력값을 변환하여 적합한 형식으로 만듦.\n",
        "- 역전파를 비활성화하고, 모델이 각 토큰에 대해 가능한 모든 단어 점수 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W2T3XriDKuJD",
      "metadata": {
        "id": "W2T3XriDKuJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e526c6ee-fb50-486c-8971-2a27b5066f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -6.0337,   4.5526,  -5.6312,  ...,  -7.3959,  -7.4220,  -5.8337],\n",
            "         [ -6.1762,   4.7585,  -7.3973,  ...,  -7.6209, -12.2124,  -6.0998],\n",
            "         [ -7.4194,   3.9148,  -6.1517,  ...,  -6.8162,  -9.5421,  -3.0473],\n",
            "         ...,\n",
            "         [ -7.3761,   8.6972,  -5.4904,  ...,  -8.7202,  -9.1403,  -5.8566],\n",
            "         [ -5.6347,  10.3884,  -4.3374,  ...,  -8.6900,  -7.4171,  -3.5043],\n",
            "         [ -5.6652,  10.3407,  -4.4099,  ...,  -8.7521,  -7.4286,  -3.6681]]])\n"
          ]
        }
      ],
      "source": [
        "# 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "# 모델에 토큰 텐서를 전달하고 예측 실행\n",
        "with torch.no_grad(): # 가중치 업데이트 없으므로 자동미분연산은 끔\n",
        "    outputs = model(tokens_tensor) # 예측. 모델은 각 토큰위치에 대한 예측 결과를 반환.\n",
        "    predictions = outputs[0] # logits (각 토큰위치에서 가능한 모든 토큰들의 원시점수)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lIkvkAL5Oalc",
      "metadata": {
        "id": "lIkvkAL5Oalc"
      },
      "source": [
        "### 5. MASK된 토큰 예측\n",
        "- [MASK] 위치에서 가장 높은 점수를 받은 토큰의 인덱스를 추출하고, 이를 단어로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MO5B91p4KwI0",
      "metadata": {
        "id": "MO5B91p4KwI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de12207-07d0-4864-b3be-bcd1f6a73315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: [CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\n",
            "Masked: ['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '사랑', '을', '했', '##다', '.', '[SEP]']\n",
            "Predicted token: 사랑\n",
            "\n",
            "Filled sentence: 열여덟 , 우리는 서로의 이름을 처음 불렀다 . 그리고 스물 하나 , 우린 사랑 을 했다 .\n"
          ]
        }
      ],
      "source": [
        "# 예측된 토큰 확인\n",
        "predicted_index = torch.argmax(predictions[0, masked_index]).item() # masked_index에 들어갈 것으로 가장 확률이 높은 인덱스\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "# 예측된 토큰으로 마스크 채우기\n",
        "tokenized_text[masked_index] = predicted_token\n",
        "# 토큰화된 텍스트를 다시 문자열로 변환\n",
        "filled_text = tokenizer.convert_tokens_to_string(tokenized_text[1:-1])\n",
        "\n",
        "print(\"Original:\", text)\n",
        "print(\"Masked:\", tokenized_text)\n",
        "print(\"Predicted token:\", predicted_token) ; print()\n",
        "\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g4ncI4tBOWLh",
      "metadata": {
        "id": "g4ncI4tBOWLh"
      },
      "source": [
        "\n",
        "### 6. MASK된 문장 복원\n",
        "- 예측된 토큰으로 [MASK]를 대체하여 완성된 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aQJBSmfZK2l2",
      "metadata": {
        "id": "aQJBSmfZK2l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ef8f78-6044-438b-d1b3-e9743e279c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base')\n",
        "\n",
        "def fill_mask(input_text):\n",
        "    # 텍스트를 토큰으로 변환\n",
        "    tokenized_text = tokenizer.tokenize(input_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # 마스킹된 위치 찾기\n",
        "    masked_index = tokenized_text.index(\"[MASK]\")\n",
        "\n",
        "    # 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # 모델에 토큰 텐서를 전달하고 예측 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0]\n",
        "\n",
        "    # 예측된 토큰 확인\n",
        "    predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "    # 마스크를 채운 문장 반환\n",
        "    tokenized_text[masked_index] = predicted_token\n",
        "    return tokenizer.convert_tokens_to_string(tokenized_text[1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yeAYIzyYPVVt",
      "metadata": {
        "id": "yeAYIzyYPVVt"
      },
      "source": [
        "예시 문장 만들어서 MLM을 사용해 보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q81b8zuYK3E9",
      "metadata": {
        "id": "Q81b8zuYK3E9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fc234c-7b83-48a1-fd5e-b2103a919bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled sentence: 이번 여름은 치맥 을 하게 될 것 같다\n"
          ]
        }
      ],
      "source": [
        "# 예시 1: \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "# 예시 2: \"[CLS] 연동운은 INSGIHT 학회를 정말 사랑한다. 그는 INSIGHT 학회를 위해 [MASK]를 했다.[SEP]\"\n",
        "# 이 예시를 참고해서 [CLS](맨 앞), [MASK](채울 부분), [SEP](맨 뒤)를 추가해서 여러분만의 예시 문장 만들어주세요\n",
        "input_text = \"[CLS] 이번 여름은 [MASK]을 하게 될 것 같다 [SEP]\" # 자유롭게 예시 문장 만들어보세요!\n",
        "filled_text = fill_mask(input_text)\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 한국어 금융 뉴스 긍정, 부정 분류"
      ],
      "metadata": {
        "id": "w6tXBQQQUUNZ"
      },
      "id": "w6tXBQQQUUNZ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VNl9yVA-UjdC",
        "outputId": "e87b8399-3ff7-4f33-a11b-eb7950bc81f9"
      },
      "id": "VNl9yVA-UjdC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finance_data.csv를 다운로드 합니다"
      ],
      "metadata": {
        "id": "MbRYkRmUcYKa"
      },
      "id": "MbRYkRmUcYKa"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecjZ0-WMUnIT",
        "outputId": "8af0639d-675a-46c5-8f70-9e4deada27be"
      },
      "id": "ecjZ0-WMUnIT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-27 13:00:43--  https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1319001 (1.3M) [text/plain]\n",
            "Saving to: ‘finance_data.csv’\n",
            "\n",
            "finance_data.csv    100%[===================>]   1.26M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-05-27 13:00:44 (124 MB/s) - ‘finance_data.csv’ saved [1319001/1319001]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('finance_data.csv')"
      ],
      "metadata": {
        "id": "EQHuMwZQUpai"
      },
      "id": "EQHuMwZQUpai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6ZMYHBd5Urli",
        "outputId": "98ae5668-07f7-4d24-c33f-3ff4ccb92348"
      },
      "id": "6ZMYHBd5Urli",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     labels                                           sentence  \\\n",
              "0   neutral  According to Gran, the company has no plans to...   \n",
              "1   neutral  Technopolis plans to develop in stages an area...   \n",
              "2  negative  The international electronic industry company ...   \n",
              "3  positive  With the new production plant the company woul...   \n",
              "4  positive  According to the company's updated strategy fo...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d542c47e-107b-4403-998e-7857425ad4b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d542c47e-107b-4403-998e-7857425ad4b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d542c47e-107b-4403-998e-7857425ad4b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d542c47e-107b-4403-998e-7857425ad4b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e40bde16-3c09-4c93-95c7-7bfff0758c5e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e40bde16-3c09-4c93-95c7-7bfff0758c5e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e40bde16-3c09-4c93-95c7-7bfff0758c5e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4846,\n  \"fields\": [\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4838,\n        \"samples\": [\n          \"The Company serves approximately 3,000 customers in over 100 countries.\",\n          \"On Dec. 1, Grimaldi acquired 1.5 million shares and a 50.1-percent stake in Finnlines.\",\n          \"The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kor_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4827,\n        \"samples\": [\n          \"YIT\\uc5d0 \\ub300\\ud55c \\uace0\\uac1d\\ub4e4\\uc758 \\uc2e0\\ub8b0 \\uc99d\\uac00\\ub294 \\uc544\\ud30c\\ud2b8 \\ub9e4\\ub9e4\\uac00 \\uac00\\uc18d\\ud654\\ub41c \\uac83\\uc73c\\ub85c \\ubcfc \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uc0dd\\uc0b0\\uc740 2010\\ub144 \\ub3d9\\uc548 \\uba55\\uc2dc\\ucf54\\uc640 \\ud5dd\\uac00\\ub9ac\\ub97c \\ud3ec\\ud568\\ud55c \\uc5d8\\ucf54\\ud14d\\uc758 \\ub2e4\\ub978 \\uc9c0\\uc5ed\\uc73c\\ub85c \\ud655\\ub300\\ub420 \\uac83\\uc774\\ub2e4.\",\n          \"\\ubc14\\uc774\\uc0b4\\ub77c\\ub294 \\ub610\\ud55c 2009\\ub144\\uc758 2\\uc5b55220\\ub9cc \\uc720\\ub85c\\uc5d0 \\ube44\\ud574 2010\\ub144\\uc5d0\\ub294 2\\uc5b55320\\ub9cc \\uc720\\ub85c\\uac00 \\uc21c\\ub9e4\\ucd9c\\ub420 \\uac83\\uc73c\\ub85c \\uc608\\uc0c1\\ud55c\\ub2e4\\uace0 \\ubc1d\\ud614\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플의 개수 :', len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1Al8N7Usnj",
        "outputId": "a927bde4-430c-4617-ba63-2635a8367773"
      },
      "id": "zG1Al8N7Usnj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 개수 : 4846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "neutral, positive. negative를 숫자로 바꿔줍니다. <br>\n",
        "neutral:0, positive:1, negative:2로 바꿀게요"
      ],
      "metadata": {
        "id": "KnjUNsEOdJzG"
      },
      "id": "KnjUNsEOdJzG"
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "fC-xK-nDUuTy",
        "outputId": "55e81992-e8aa-457b-fadc-2e7f9d5fd208"
      },
      "id": "fC-xK-nDUuTy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-910beaa298a3>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   labels                                           sentence  \\\n",
              "0       0  According to Gran, the company has no plans to...   \n",
              "1       0  Technopolis plans to develop in stages an area...   \n",
              "2       2  The international electronic industry company ...   \n",
              "3       1  With the new production plant the company woul...   \n",
              "4       1  According to the company's updated strategy fo...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c416183e-a07d-4d7f-9a9d-945f4947fa50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c416183e-a07d-4d7f-9a9d-945f4947fa50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c416183e-a07d-4d7f-9a9d-945f4947fa50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c416183e-a07d-4d7f-9a9d-945f4947fa50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-118ec66d-f046-487a-9a33-587aeee6d5a1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-118ec66d-f046-487a-9a33-587aeee6d5a1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-118ec66d-f046-487a-9a33-587aeee6d5a1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4846,\n  \"fields\": [\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4838,\n        \"samples\": [\n          \"The Company serves approximately 3,000 customers in over 100 countries.\",\n          \"On Dec. 1, Grimaldi acquired 1.5 million shares and a 50.1-percent stake in Finnlines.\",\n          \"The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kor_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4827,\n        \"samples\": [\n          \"YIT\\uc5d0 \\ub300\\ud55c \\uace0\\uac1d\\ub4e4\\uc758 \\uc2e0\\ub8b0 \\uc99d\\uac00\\ub294 \\uc544\\ud30c\\ud2b8 \\ub9e4\\ub9e4\\uac00 \\uac00\\uc18d\\ud654\\ub41c \\uac83\\uc73c\\ub85c \\ubcfc \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uc0dd\\uc0b0\\uc740 2010\\ub144 \\ub3d9\\uc548 \\uba55\\uc2dc\\ucf54\\uc640 \\ud5dd\\uac00\\ub9ac\\ub97c \\ud3ec\\ud568\\ud55c \\uc5d8\\ucf54\\ud14d\\uc758 \\ub2e4\\ub978 \\uc9c0\\uc5ed\\uc73c\\ub85c \\ud655\\ub300\\ub420 \\uac83\\uc774\\ub2e4.\",\n          \"\\ubc14\\uc774\\uc0b4\\ub77c\\ub294 \\ub610\\ud55c 2009\\ub144\\uc758 2\\uc5b55220\\ub9cc \\uc720\\ub85c\\uc5d0 \\ube44\\ud574 2010\\ub144\\uc5d0\\ub294 2\\uc5b55320\\ub9cc \\uc720\\ub85c\\uac00 \\uc21c\\ub9e4\\ucd9c\\ub420 \\uac83\\uc73c\\ub85c \\uc608\\uc0c1\\ud55c\\ub2e4\\uace0 \\ubc1d\\ud614\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 dataframe을 dataset 객체로 변환해줍니다"
      ],
      "metadata": {
        "id": "UFpwMzt7dbOf"
      },
      "id": "UFpwMzt7dbOf"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "all_data = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "9EtcjYQ9U24T"
      },
      "id": "9EtcjYQ9U24T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndnRYYyxVG3F",
        "outputId": "f510c688-5560-4cd1-cfc8-67fce5dd66bd"
      },
      "id": "ndnRYYyxVG3F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 4846\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all_data를 train과 test로 나눠줍니다<br>\n",
        "train : test = 4 : 1로 나눠줍니다"
      ],
      "metadata": {
        "id": "XtUTOhy-df74"
      },
      "id": "XtUTOhy-df74"
    },
    {
      "cell_type": "code",
      "source": [
        "cs = all_data.train_test_split(test_size=0.2)\n",
        "\n",
        "train_cs = cs['train']\n",
        "test_cs = cs['test']"
      ],
      "metadata": {
        "id": "Oauj0GccVJNt"
      },
      "id": "Oauj0GccVJNt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI-P3-anVlgQ",
        "outputId": "ed352b7b-9521-46a6-bf80-c904b905adff"
      },
      "id": "WI-P3-anVlgQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 3876\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLum1NfiVmtf",
        "outputId": "4538d132-ee7b-4dba-9d72-499dbc57897d"
      },
      "id": "tLum1NfiVmtf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 970\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----train_cs-----\")\n",
        "print(train_cs)\n",
        "print(\"-----test_cs-----\")\n",
        "print(test_cs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwLbKD21VtsZ",
        "outputId": "6c227576-86b0-4f15-cb1e-d525c0c2a252"
      },
      "id": "UwLbKD21VtsZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----train_cs-----\n",
            "Dataset({\n",
            "    features: ['labels', 'sentence', 'kor_sentence'],\n",
            "    num_rows: 3876\n",
            "})\n",
            "-----test_cs-----\n",
            "Dataset({\n",
            "    features: ['labels', 'sentence', 'kor_sentence'],\n",
            "    num_rows: 970\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 샘플과, 샘플에 해당하는 레이블을 출력합니다.<br>\n",
        "레이블은 0: neutral, 1: positive, 2: negative였죠"
      ],
      "metadata": {
        "id": "Gs-zl-yheGsy"
      },
      "id": "Gs-zl-yheGsy"
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플:', train_cs['kor_sentence'][0])\n",
        "print('샘플의 레이블:', train_cs['labels'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE5NJBnCWA1R",
        "outputId": "50ad0309-9b4b-4c01-b1f4-96dc3684475d"
      },
      "id": "SE5NJBnCWA1R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플: (ADP뉴스) - 2009년 12월 1일 - 핀란드의 식기 및 수공구 제조업체인 Fiskars Oyj Abp (HEL : FISAS)는 자회사인 이탈라 그룹의 총 18명의 사무 및 관리 직원을 예비로 만들 것이라고 오늘 밝혔다.\n",
            "샘플의 레이블: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss"
      ],
      "metadata": {
        "id": "ZaKsc7NEWDN6"
      },
      "id": "ZaKsc7NEWDN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 `[CLS] 문장 [SEP]` 구조를 만듭니다.\n"
      ],
      "metadata": {
        "id": "_B8aU2LzeSit"
      },
      "id": "_B8aU2LzeSit"
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train_cs['kor_sentence']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test_cs['kor_sentence']))"
      ],
      "metadata": {
        "id": "PzNtwi-IXUoR"
      },
      "id": "PzNtwi-IXUoR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, validation, test에 대해 labels 정보만 따로 저장합니다"
      ],
      "metadata": {
        "id": "UBw9FB0MeV80"
      },
      "id": "UBw9FB0MeV80"
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_cs['labels']\n",
        "test_labels = test_cs['labels']"
      ],
      "metadata": {
        "id": "XcvXe3M1XVvR"
      },
      "id": "XcvXe3M1XVvR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_sentences와 test_labels를 확인합니다"
      ],
      "metadata": {
        "id": "bnTxuaXDeael"
      },
      "id": "bnTxuaXDeael"
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKnDY47YXXD5",
        "outputId": "26096f58-c6fc-49c8-feed-ab30c49b15a6"
      },
      "id": "TKnDY47YXXD5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] Tekla의 부사장인 Risto Raty는 Tekla Structures와 ArchiCAD가 건설 프로젝트 전반에 걸쳐 전체 설계 및 문서화 워크플로우를 다룰 것이라고 말했습니다. [SEP]',\n",
              " '[CLS] 2006년 텔리아소네라 순매출액은 91억 크로네, EBITDA 순매출액은 32.266억 크로네, 순이익은 19.28억 크로네였다. [SEP]',\n",
              " '[CLS] 2011년 2월 4일 - 핀란드의 개인 정보 보호 및 보안 소프트웨어 개발업체 Tetia Oyj (HEL : TEC1V)는 두 가지 전략 사업부를 설립했다고 수요일에 밝혔다. [SEP]',\n",
              " '[CLS] 양국 간 사업 연계도 확대되고 있기 때문에 인도가 우리의 우선순위가 높습니다\"라고 Thornstrom은 말했다. [SEP]',\n",
              " '[CLS] 2010년 한 해 동안 긍정적인 영업실적과 금액은 여름 말까지 주문흡수량에 따라 달라질 것이라며 순매출과 영업실적이 전년보다 개선될 것으로 기대하고 있다. [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCd1t7anXYcI",
        "outputId": "1b529428-79d0-42cd-de03-a67ca6e0c671"
      },
      "id": "fCd1t7anXYcI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer와 model을 불러옵니다.<br>\n",
        "tokenizer로는 BertTokenizer를 사용하고, model은 분류모델인 BertForSequenceClassification을 사용합니다<br>\n",
        "우리는 neutral, negative, positive중에 하나를 예측해야 하므로, num_labels에 3을 넣어서 model에 num_labels를 넘겨줍니다"
      ],
      "metadata": {
        "id": "O-DF8jY-ec7t"
      },
      "id": "O-DF8jY-ec7t"
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 BERT 중 하나인 'klue/bert-base'를 사용.\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base') # 사전학습 된 상태로 불러옵니다\n",
        "\n",
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels) # 사전학습 된 상태로 불러옵니다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vfBq29yXagY",
        "outputId": "d3d8c77a-c44a-49c1-ae48-9ca9bd4f0e86"
      },
      "id": "0vfBq29yXagY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래 BERT는 max_length가 512지만, 128로 축소해서 학습하면 더 빠른 시간에 학습이 가능합니다.\n",
        "# MAX_LEN을 128로 하고, 성능이 좋지 않으면 MAX_LEN을 256 -> 384 -> 512로 늘려가며 비교하는 것도 방법입니다\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 실습때 했던 encode_korquad_examples() 함수 기억하시나요? 그 함수와 유사하게 작성되었습니다.\n",
        "def encode_classification_data(sentences, labels):\n",
        "    encodings = tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encodings['input_ids']\n",
        "    attention_mask = encodings['attention_mask']\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "xADUO_97Xb6h"
      },
      "id": "xADUO_97Xb6h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, validation, test 데이터셋을 생성합니다"
      ],
      "metadata": {
        "id": "3eTT7qU4fX1B"
      },
      "id": "3eTT7qU4fX1B"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = encode_classification_data(train_sentences, train_labels)\n",
        "test_dataset = encode_classification_data(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "J_o3v1GaXeEY"
      },
      "id": "J_o3v1GaXeEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터의 크기:', len(train_dataset))\n",
        "print('테스트 데이터의 크기:', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3XCY79hX8lz",
        "outputId": "0a045fca-aa56-4463-ff3a-0f6ee63932a5"
      },
      "id": "n3XCY79hX8lz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기: 3876\n",
            "테스트 데이터의 크기: 970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader를 생성합니다"
      ],
      "metadata": {
        "id": "iwWu8eunfd3C"
      },
      "id": "iwWu8eunfd3C"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=RandomSampler(train_dataset),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=SequentialSampler(test_dataset),  # 테스트도 일반적으로 Sequential을 씀\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "p1lKV4xDYMHE"
      },
      "id": "p1lKV4xDYMHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 지정\n",
        "# AdamW 사용합니다\n",
        "# AdamW에 모델의 파라미터 정보를 넘겨줍니다.\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps = 1e-8)"
      ],
      "metadata": {
        "id": "evpOx_OKYFDs"
      },
      "id": "evpOx_OKYFDs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 학습합니다"
      ],
      "metadata": {
        "id": "ExHpHot8f9-z"
      },
      "id": "ExHpHot8f9-z"
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # gpu 사용 가능하면 gpu(cuda)로, 그렇지 않으면 cpu로\n",
        "model.to(device)\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "    total_loss = 0\n",
        "\n",
        "    model.eval() # 모델을 학습 모드로 설정합니다\n",
        "\n",
        "    loop = tqdm(train_dataloader, desc=f'Epoch {epoch_i + 1}', leave=False)\n",
        "\n",
        "    for step, batch in enumerate(loop):\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "        optimizer.zero_grad() # 가중치 0으로 초기화\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward() # 역전파\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step() # 파라미터 업데이트\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(f\"\\n  Average training loss: {avg_train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqMeGbE3ZFnJ",
        "outputId": "5c6ccc97-35d5-4f5b-d2e9-e83c64c8325c"
      },
      "id": "FqMeGbE3ZFnJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.4833\n",
            "\n",
            "======== Epoch 2 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.2243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 모델의 가중치를 저장합니다"
      ],
      "metadata": {
        "id": "r0iyJ85EgmYH"
      },
      "id": "r0iyJ85EgmYH"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"BERT_news.pt\")"
      ],
      "metadata": {
        "id": "7qBYAElLZwUU"
      },
      "id": "7qBYAElLZwUU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 가중치를 다시 불러옵니다<br>\n",
        "- 지금처럼 학습과 테스트를 한 번에 이어서 할 때는 모델 가중치를 다시 불러올 필요가 없습니다.\n",
        "- 그러나 내가 이전에 학습한 모델을 사용해서 예측을 수행하고 싶을 때는 다음과 같이 이전에 학습된 가중치를 불러와야 합니다"
      ],
      "metadata": {
        "id": "j4efz5digorv"
      },
      "id": "j4efz5digorv"
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels)\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "model.load_state_dict(torch.load(\"BERT_news.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_yPgKZMazGi",
        "outputId": "ee95decf-6ca9-46b1-b3f4-a0cf24cd4f90"
      },
      "id": "n_yPgKZMazGi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가하기 위한 함수를 정의합니다"
      ],
      "metadata": {
        "id": "xxZpNjrQf8D8"
      },
      "id": "xxZpNjrQf8D8"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(preds, labels):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'f1_macro': f1_score(labels, preds, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(labels, preds, average='micro', zero_division=0),\n",
        "        'f1_weighted': f1_score(labels, preds, average='weighted', zero_division=0)\n",
        "    }"
      ],
      "metadata": {
        "id": "oafGGaIEflTT"
      },
      "id": "oafGGaIEflTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터에 대해 평가를 수행합니다"
      ],
      "metadata": {
        "id": "TlpErKvug2Zo"
      },
      "id": "TlpErKvug2Zo"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "    logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 예측 결과 저장\n",
        "    accum_logits.extend(np.argmax(logits, axis=1))\n",
        "    accum_label_ids.extend(label_ids)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "\n",
        "# 메트릭 계산\n",
        "results = compute_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "# 출력\n",
        "print(\"\\n[✔️ Test Evaluation Result]\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS5RSE5DaBEF",
        "outputId": "1da0cc76-5ede-4324-f225-531993e12ca4"
      },
      "id": "aS5RSE5DaBEF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:06<00:00,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[✔️ Test Evaluation Result]\n",
            "Accuracy: 0.8557\n",
            "F1 (Macro) Score: 0.8241\n",
            "F1 (Micro) Score: 0.8557\n",
            "F1 (Weighted) Score: 0.8539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace transformers 라이브러리의 pipeline API를 활용하면 텍스트 분류 모델을 추론하기 위한 설정을 편리하게 할 수 있습니다"
      ],
      "metadata": {
        "id": "rxoXjbl0g4zA"
      },
      "id": "rxoXjbl0g4zA"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipe = pipeline(\"text-classification\", # 수행할 작업: 텍스트 분류\n",
        "                model=model.to(device), # 사용할 모델\n",
        "                tokenizer=tokenizer, # 모델에 맞는 토크나이저\n",
        "                max_length=512, # 입력 문장 최대 길이\n",
        "                return_all_scores=True, # 모든 클래스의 확률 반환\n",
        "                function_to_apply='softmax' # softmax 사용\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cenQIx_JZxe1",
        "outputId": "f7667b15-312a-45fe-ed53-d701f069eecf"
      },
      "id": "cenQIx_JZxe1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('SK하이닉스가 매출이 급성장하였다') # 이 문장에 대해 label 점수를 보면\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_KLJZK_bN9t",
        "outputId": "26309159-9438-4a77-c481-5005689fcbb5"
      },
      "id": "c_KLJZK_bN9t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.012707731686532497}, {'label': 'LABEL_1', 'score': 0.9851004481315613}, {'label': 'LABEL_2', 'score': 0.002191875595599413}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_all_scores = True로 했기 때문에 LABEL_0, LABEL_1, LABEL_2의 모든 score가 다 출력됩니다"
      ],
      "metadata": {
        "id": "VZm_pLmliBOW"
      },
      "id": "VZm_pLmliBOW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL_0, LABEL_1, LABEL_2 대신에 중립, 긍정, 부정으로 출력하도록 label_dict를 설정합니다"
      ],
      "metadata": {
        "id": "lDxA2TsniGbA"
      },
      "id": "lDxA2TsniGbA"
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}"
      ],
      "metadata": {
        "id": "ms8u3r6TbCRk"
      },
      "id": "ms8u3r6TbCRk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "label_dict에서 LABEL_0, LABEL_1, LABEL_2를 중립, 긍정, 부정으로 바꿔서 출력하는 함수를 정의합니다"
      ],
      "metadata": {
        "id": "sZ5sItmTiSIh"
      },
      "id": "sZ5sItmTiSIh"
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(text):\n",
        "  result = pipe(text)\n",
        "\n",
        "  return [label_dict[result[0]['label']]]"
      ],
      "metadata": {
        "id": "sFdQKVVLbEG7"
      },
      "id": "sFdQKVVLbEG7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전의 pileline 코드에서 return_all_scores를 제거합니다. return_all_scores는 default가 False입니다\n",
        "pipe = pipeline(\"text-classification\", model=model.to(device), tokenizer=tokenizer, max_length=512,function_to_apply='softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZQ9u9jibfwW",
        "outputId": "9a1e5cd7-ae5a-4ac4-d621-d328833c2009"
      },
      "id": "8ZQ9u9jibfwW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MoC1FFDbii-",
        "outputId": "8bc84f53-3e3e-4e02-8e49-3c1e06695586"
      },
      "id": "1MoC1FFDbii-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_1', 'score': 0.9851004481315613}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_all_scores를 False로 했으므로 가장 높은 score의 LABEL만 출력됩니다"
      ],
      "metadata": {
        "id": "hrs7W6Rqic9R"
      },
      "id": "hrs7W6Rqic9R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction 함수를 사용하여 다양한 금융 텍스트의 긍정/부정/중립을 분석해보면"
      ],
      "metadata": {
        "id": "SFTC9xoMiruT"
      },
      "id": "SFTC9xoMiruT"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('SK하이닉스가 매출이 급성장하였다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPs7syKa69T",
        "outputId": "eedd4f73-c4e9-430c-bb4b-28806292c82e"
      },
      "id": "UhPs7syKa69T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['긍정']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('ChatGPT의 등장으로 인공지능 스타트업들은 비상이다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPmPUwUeblDG",
        "outputId": "1c8b4e8c-a4fe-4d68-d2a5-8c853be436c3"
      },
      "id": "kPmPUwUeblDG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['긍정']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('인공지능 기술의 발전으로 누군가는 기회를 얻을 것이고, 누군가는 얻지 못할 것이다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6QE8Ki_bmS3",
        "outputId": "73b12ac1-e05b-4f42-ac1c-518623a5fef3"
      },
      "id": "f6QE8Ki_bmS3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['중립']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('삼성전자의 주가가 상승곡선을 그리고 있다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiGbXQYIbm2O",
        "outputId": "e98ca8c6-1c32-4027-d506-4be1d3bfce40"
      },
      "id": "RiGbXQYIbm2O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['긍정']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zqfEZ0wkPsLA",
      "metadata": {
        "id": "zqfEZ0wkPsLA"
      },
      "source": [
        "# 2. Text Generation : GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_VV4vozKQM4C",
      "metadata": {
        "id": "_VV4vozKQM4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993ce387-a055-4136-bc14-2c7e643e8d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "눈을 떠보니 낯선 하얀 천장이 보였다!\n",
            "\"이거, 이게 뭐야?\"\n",
            "그녀는 고개를 끄덕였다.\n",
            "그리고는 다시 한 번 주위를 둘러보았다.\n",
            "아무래도 그건 좀 이상했다.\n",
            "'아, 저기!'\n",
            "그는 잠시 망설이는 듯하다가 이윽고 입을 열었다.\n",
            "그러자 갑자기 그의 눈이 커졌다.\n",
            "그의 눈동자가 점점 커지며 그녀의 입에서 흘러나왔다.\n",
            "마치 그가 자신의 손을 잡고 있는 것 같았다.\n",
            "눈을 뜨고 보니 그는 이미 자신이 알고 있던 것을 모두 잊은 상태였다.\n",
            "하지만 그녀는 여전히 자신을 바라보고 있었다.\n",
            "어쩌면 그녀가 지금 자신에게 하고 싶은 말을 다 할 수 있을지도 모른다는 생각이 들었다.\n",
            "그러나 그것은 곧 현실이\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "# 시작 텍스트 설정\n",
        "# 예시 text = '인사이트 13기 회장, 부회장은 과연 누가 될까? 너무 기대된다'\n",
        "# 예시 텍스트 말고 다른 text 직접 입력해보세요! 기발한 아이디어 기다립니다ㅎㅎ\n",
        "text = '눈을 떠보니 낯선 하얀 천장이 보였다'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "\n",
        "# 텍스트 생성\n",
        "gen_ids = model.generate(input_ids,\n",
        "                         max_length=128,\n",
        "                         repetition_penalty=2.0,\n",
        "                         pad_token_id=tokenizer.pad_token_id,\n",
        "                         early_stopping=True,\n",
        "                         eos_token_id=tokenizer.eos_token_id,\n",
        "                         bos_token_id=tokenizer.bos_token_id,\n",
        "                         use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![스크린샷 2025-05-25 181321.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "UKNpok8MucIw"
      },
      "id": "UKNpok8MucIw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㅋㅋㅋㅋ 회장, 부회장의 단어를 보고 인사이트를 기업으로 인식한 거 같아요"
      ],
      "metadata": {
        "id": "TBrGpnyIT1NH"
      },
      "id": "TBrGpnyIT1NH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "과제 끝!!"
      ],
      "metadata": {
        "id": "Zf7ovu23T0Q2"
      },
      "id": "Zf7ovu23T0Q2"
    },
    {
      "cell_type": "markdown",
      "id": "v3BcoUr_GTnJ",
      "metadata": {
        "id": "v3BcoUr_GTnJ"
      },
      "source": [
        "# 3. Langchain ~ Rag (참고)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y7dig7dRIkF8",
      "metadata": {
        "id": "Y7dig7dRIkF8"
      },
      "source": [
        "### Langchain\n",
        "- LLM을 사용한 어플리케이션 개발 단순화를 위한 프레임워크\n",
        "- python과 JavaScript 라이브러리 제공\n",
        "- 요약, 번역, 챗봇, QnA, 데이터 증강(Augmentation) 등의 서비스 구현 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7pc9jY4dJYGO",
      "metadata": {
        "id": "7pc9jY4dJYGO"
      },
      "source": [
        "### RAG\n",
        "- LLM 모델의 단점 중 사실 관계 오류 가능성과 맥락 이해의 한계를 개선하는데 초점을 맞춘 방법\n",
        "- 외부 지식 베이스를 연결해 모델의 생성 능력과 사실 관계 파악 능력 향상\n",
        "- 할루시네이션 감소와 최신 정보 반영에 유리"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드 실행하려면 OPEN AI의 langchain API Key가 필요한데, 현재는 유료라서... 그냥 실행하지 말고 보기만 해주세요"
      ],
      "metadata": {
        "id": "gtwJGlpKToym"
      },
      "id": "gtwJGlpKToym"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G3lzSLe4GUUX",
      "metadata": {
        "id": "G3lzSLe4GUUX"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WqF4ImUyHazE",
      "metadata": {
        "id": "WqF4ImUyHazE"
      },
      "source": [
        "## 1. 데이터 가져오기\n",
        "- 분석할 문서를 불러와 데이터 파이프라인의 입력으로 사용\n",
        "- 자연어 처리를 수행하기 위해 원천 데이터를 준비하는 단계\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VwuthDp5GaZB",
      "metadata": {
        "id": "VwuthDp5GaZB"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "documents = TextLoader(\"AI.txt\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ICqSGfl2HjgE",
      "metadata": {
        "id": "ICqSGfl2HjgE"
      },
      "source": [
        "## 2. 텍스트 분할\n",
        "- 긴 문서를 일정 크기의 청크로 나눠 처리 가능하도록 만듦\n",
        "- 검색 효율성과 모델의 입력 제약을 고려한 전처리 작업\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qx5bjqBxGcDU",
      "metadata": {
        "id": "qx5bjqBxGcDU"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 문서를 청크로 분할\n",
        "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "# docs 변수에 분할 문서를 저장\n",
        "docs = split_docs(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7v-0gnNJHn_M",
      "metadata": {
        "id": "7v-0gnNJHn_M"
      },
      "source": [
        "## 3. 임베딩 변환\n",
        "- 텍스트 데이터를 벡터 공간으로 매핑하여 기계 학습 모델이 이해할 수 있는 수치 데이터로 변환\n",
        "- 텍스트의 의미적 유사성을 계산하고 처리를 자동화하기 위한 단계\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3rtyWeKHGfwc",
      "metadata": {
        "id": "3rtyWeKHGfwc"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RA02sWNfIFsI",
      "metadata": {
        "id": "RA02sWNfIFsI"
      },
      "source": [
        "## 4. 벡터 저장\n",
        "- 변환된 벡터 데이터를 데이터베이스에 저장하여 고속 검색과 활용 지원\n",
        "- 효율적인 질의 응답 및 문서 검색 시스템 구현을 위한 핵심 단계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cV0ab-ryIDKw",
      "metadata": {
        "id": "cV0ab-ryIDKw"
      },
      "outputs": [],
      "source": [
        "# Chromdb에 벡터 저장\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4wZXuxWKHp7Y",
      "metadata": {
        "id": "4wZXuxWKHp7Y"
      },
      "source": [
        "## 5. 질문 응답\n",
        "- 입력된 질문과 관련된 문서를 검색한 뒤 GPT 모델로 답변 생성\n",
        "- 사용자 질문에 적합한 답변을 제공하기 위해 유사 문서 검색과 자연어 처리를 결합한 핵심 과정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JLg25a9sGhnC",
      "metadata": {
        "id": "JLg25a9sGhnC"
      },
      "outputs": [],
      "source": [
        "import os #운영체제(os) 모듈을 가져올 때 사용되는 라이브러리\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\" #openai 키 입력 -> 현재 유료로 사용 가능,,,ㅠㅠ\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "model_name = \"gpt-3.5-turbo\"  #GPT-3.5 turbo 모델 사용\n",
        "llm = ChatOpenAI(model_name=model_name)\n",
        "\n",
        "# Q&A 체인을 사용하여 쿼리에 대한 답변 얻기\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=True)\n",
        "\n",
        "# 쿼리를 작성하고 유사성 검색을 수행하여 답변을 생성,따라서 txt에 있는 내용을 질의해야 합니다\n",
        "query = \"AI란?\"\n",
        "matching_docs = db.similarity_search(query)\n",
        "answer =  chain.run(input_documents=matching_docs, question=query)\n",
        "answer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "721.212px",
        "left": "71px",
        "top": "87.7936px",
        "width": "302.538px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}