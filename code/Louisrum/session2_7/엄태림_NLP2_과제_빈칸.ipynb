{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "s5BK0Ab4F_28",
      "metadata": {
        "id": "s5BK0Ab4F_28"
      },
      "source": [
        "# 1. NLP 이론문제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XbPvxoevT-wC",
      "metadata": {
        "id": "XbPvxoevT-wC"
      },
      "source": [
        "## 문제 1\n",
        "일반 attention에 반해 self attention가 지닌 특징을 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tns2mhzVUM6t",
      "metadata": {
        "id": "Tns2mhzVUM6t"
      },
      "source": [
        "답 : 시퀸스에 있는 모든 단어들이 서로 역할을 바꿔가며 한 단어가 쿼리의 역할을 하면, 나머지 단어들이 키와 벨류 역할을 하면서 모든 단어에 이러한 관계를 만들어낸다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kaAY-zLvUVHF",
      "metadata": {
        "id": "kaAY-zLvUVHF"
      },
      "source": [
        "## 문제 2\n",
        "BERT에 대한 설명이 아닌 것은?\n",
        "\n",
        "a) 사전 학습 모델\n",
        "\n",
        "b) 양방향 문맥 이해\n",
        "\n",
        "c) 트랜스포머의 디코더를 쌓아 올린 구조\n",
        "\n",
        "d) 이후 RoBERTa와 ALBERT로 발전"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N9kPuYF2UOpO",
      "metadata": {
        "id": "N9kPuYF2UOpO"
      },
      "source": [
        "답 : c"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9mHJHJVT-nA",
      "metadata": {
        "id": "c9mHJHJVT-nA"
      },
      "source": [
        "## 문제 3\n",
        "BERT와 GPT의 학습 방식 차이를 간단히 설명하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0FsqYppaUO-6",
      "metadata": {
        "id": "0FsqYppaUO-6"
      },
      "source": [
        "답 : 버트는 트랜스포머의 인코더만을 사용해 학습하지만, gpt는 디코더만 사용해서 학습함"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gpQU3DA-T-eR",
      "metadata": {
        "id": "gpQU3DA-T-eR"
      },
      "source": [
        "## 문제 4\n",
        "LLM이 지닌 한계와 Rag의 필요성에 대해 간단히 서술하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kYc85pSaT-a5",
      "metadata": {
        "id": "kYc85pSaT-a5"
      },
      "source": [
        "답 : llm은 기본적으로 데이터 학습에 매우 많은 자본이 필요하기 때문에, 학습 정보 업데이트 시점이 현재와 다를 수 있고, 아직까지도 일부 할루시네이션이 발생해 거짓 정보를 생성하기도 한다. 하지만 rag는 외부 지식 베이스를 연결해 정보를 찾아서 가져온 뒤, 모델의 생성능력을 결합해 사실관계 오류 가능성과 맥락 이해의 한계를 개선할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OsVU927lLs2Z",
      "metadata": {
        "id": "OsVU927lLs2Z"
      },
      "source": [
        "# 1. BERT 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AMZ40xeWMFIu",
      "metadata": {
        "id": "AMZ40xeWMFIu"
      },
      "source": [
        "**BERT (Bidirectional Encoder Representations from Transformers)**\n",
        "- 문장 분류(스팸 메일 탐지), 질의응답 시스템(챗봇, 검색 엔진), 번역(다국어 지원), 텍스트 요약(뉴스 요약) 등 다양한 NLP 작업에 사용\n",
        "- 문맥을 양방향으로 이해하여 텍스트의 의미를 정밀하게 파악하며, 사전 학습된 모델을 기반으로 빠르게 응용 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "inLp1BtKM_e7",
      "metadata": {
        "id": "inLp1BtKM_e7"
      },
      "source": [
        "### 1. 모델과 tokenizer 초기화\n",
        "- tokenizer를 통해 문장을 토큰으로 나누고, 이를 정수 인덱스로 변환하여 모델이 이해할 수 있도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "r1m1YLY3GNM0",
      "metadata": {
        "id": "r1m1YLY3GNM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31b114a-e64d-49a1-f57d-cdfe2f20534b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 tokenizer 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "# tokenizer : raw text를 개별 토큰으로 분리(Wordpiece). 토크나이저 사전에 따라 고유한 정수 인덱스(고정값)를 매핑함.\n",
        "\n",
        "# tokenizer를 통해 생성된 정수 인덱스 : 텍스트를 모델이 읽을 수 있도록 숫자화\n",
        "# Embedding vector : 단어의 의미적, 문맥적 특성을 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UJ4zRzObNqAd",
      "metadata": {
        "id": "UJ4zRzObNqAd"
      },
      "source": [
        "### 2. 입력 텍스트 준비 및 토큰화\n",
        "- [MASK] 토큰을 삽입한 문장을 설정하고, tokenizer.tokenize()로 텍스트 토큰화\n",
        "- [MASK]를 활용하여 문맥 속에서 특정 단어를 추론하는 상황을 만들고, 이를 모델이 학습한 패턴과 비교하도록 함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "JKUXDaU1GRwy",
      "metadata": {
        "id": "JKUXDaU1GRwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e2a27e-04a6-471f-d44d-bf645c9899f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '[MASK]', '을', '했', '##다', '.', '[SEP]']\n",
            "[2, 1432, 2173, 3542, 16, 3616, 2259, 4084, 2079, 3934, 2069, 3790, 6895, 2062, 18, 3673, 10514, 3657, 16, 8983, 4, 1498, 1902, 2062, 18, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트할 문장\n",
        "text = \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "\n",
        "# 문장을 토큰으로 변환\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "print(tokenized_text)\n",
        "print(indexed_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nrWA_XEN4I3",
      "metadata": {
        "id": "_nrWA_XEN4I3"
      },
      "source": [
        "### 3. MASK된 위치 확인\n",
        "- [MASK] 토큰의 위치를 탐지해 해당 위치에서 모델이 단어를 예측하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "tAOGhKOrKrRC",
      "metadata": {
        "id": "tAOGhKOrKrRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6a2ea8-3f71-43eb-e9a0-913ba0314a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "# 마스킹된 위치 찾기\n",
        "masked_index = tokenized_text.index(\"[MASK]\") ; print(masked_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T3oqIAqDOEo_",
      "metadata": {
        "id": "T3oqIAqDOEo_"
      },
      "source": [
        "### 4. 정수화된 토큰 인덱스를 tensor로 변환 후 모델 예측 실행\n",
        "- 모델은 텐서 데이터 구조를 필요로 하므로, 입력값을 변환하여 적합한 형식으로 만듦.\n",
        "- 역전파를 비활성화하고, 모델이 각 토큰에 대해 가능한 모든 단어 점수 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "W2T3XriDKuJD",
      "metadata": {
        "id": "W2T3XriDKuJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48397758-9189-4fcb-e8b2-993686d2e422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -6.0337,   4.5526,  -5.6312,  ...,  -7.3959,  -7.4220,  -5.8337],\n",
            "         [ -6.1762,   4.7585,  -7.3973,  ...,  -7.6209, -12.2124,  -6.0998],\n",
            "         [ -7.4194,   3.9148,  -6.1517,  ...,  -6.8162,  -9.5421,  -3.0473],\n",
            "         ...,\n",
            "         [ -7.3761,   8.6972,  -5.4904,  ...,  -8.7202,  -9.1403,  -5.8566],\n",
            "         [ -5.6347,  10.3884,  -4.3374,  ...,  -8.6900,  -7.4171,  -3.5043],\n",
            "         [ -5.6652,  10.3407,  -4.4099,  ...,  -8.7521,  -7.4286,  -3.6681]]])\n"
          ]
        }
      ],
      "source": [
        "# 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "# 모델에 토큰 텐서를 전달하고 예측 실행\n",
        "with torch.no_grad(): # 가중치 업데이트 없으므로 자동미분연산은 끔\n",
        "    outputs = model(tokens_tensor) # 예측. 모델은 각 토큰위치에 대한 예측 결과를 반환.\n",
        "    predictions = outputs[0] # logits (각 토큰위치에서 가능한 모든 토큰들의 원시점수)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lIkvkAL5Oalc",
      "metadata": {
        "id": "lIkvkAL5Oalc"
      },
      "source": [
        "### 5. MASK된 토큰 예측\n",
        "- [MASK] 위치에서 가장 높은 점수를 받은 토큰의 인덱스를 추출하고, 이를 단어로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "MO5B91p4KwI0",
      "metadata": {
        "id": "MO5B91p4KwI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031a79fa-6605-4523-f20d-f9403ec535b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: [CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\n",
            "Masked: ['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '사랑', '을', '했', '##다', '.', '[SEP]']\n",
            "Predicted token: 사랑\n",
            "\n",
            "Filled sentence: 열여덟 , 우리는 서로의 이름을 처음 불렀다 . 그리고 스물 하나 , 우린 사랑 을 했다 .\n"
          ]
        }
      ],
      "source": [
        "# 예측된 토큰 확인\n",
        "predicted_index = torch.argmax(predictions[0, masked_index]).item() # masked_index에 들어갈 것으로 가장 확률이 높은 인덱스\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "# 예측된 토큰으로 마스크 채우기\n",
        "tokenized_text[masked_index] = predicted_token\n",
        "# 토큰화된 텍스트를 다시 문자열로 변환\n",
        "filled_text = tokenizer.convert_tokens_to_string(tokenized_text[1:-1])\n",
        "\n",
        "print(\"Original:\", text)\n",
        "print(\"Masked:\", tokenized_text)\n",
        "print(\"Predicted token:\", predicted_token) ; print()\n",
        "\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g4ncI4tBOWLh",
      "metadata": {
        "id": "g4ncI4tBOWLh"
      },
      "source": [
        "\n",
        "### 6. MASK된 문장 복원\n",
        "- 예측된 토큰으로 [MASK]를 대체하여 완성된 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aQJBSmfZK2l2",
      "metadata": {
        "id": "aQJBSmfZK2l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efe0571-d3d5-4dd2-d752-7db2e78d68c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base')\n",
        "\n",
        "def fill_mask(input_text):\n",
        "    # 텍스트를 토큰으로 변환\n",
        "    tokenized_text = tokenizer.tokenize(input_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # 마스킹된 위치 찾기\n",
        "    masked_index = tokenized_text.index(\"[MASK]\")\n",
        "\n",
        "    # 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # 모델에 토큰 텐서를 전달하고 예측 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0]\n",
        "\n",
        "    # 예측된 토큰 확인\n",
        "    predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "    # 마스크를 채운 문장 반환\n",
        "    tokenized_text[masked_index] = predicted_token\n",
        "    return tokenizer.convert_tokens_to_string(tokenized_text[1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yeAYIzyYPVVt",
      "metadata": {
        "id": "yeAYIzyYPVVt"
      },
      "source": [
        "예시 문장 만들어서 MLM을 사용해 보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Q81b8zuYK3E9",
      "metadata": {
        "id": "Q81b8zuYK3E9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46add6c9-3ae9-4b18-d16c-e67f5a25e16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled sentence: AI가 분석한 결과 , 김민지 , 김윤서 , 김일호 , 김재성 , 김찬우 , 김현서 , 노승혁 , 류한결 , 문건우 , 문선아 , 엄태림 , 윤해민 , 이종현 , 이지현 , 황종빈 이렇게 총 15 명의 INSGIHT의 13기 학회원 중 차기 회장은 문재인 이다 .\n"
          ]
        }
      ],
      "source": [
        "# 예시 1: \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "# 예시 2: \"[CLS] 연동운은 INSGIHT 학회를 정말 사랑한다. 그는 INSIGHT 학회를 위해 [MASK]를 했다.[SEP]\"\n",
        "# 이 예시를 참고해서 [CLS](맨 앞), [MASK](채울 부분), [SEP](맨 뒤)를 추가해서 여러분만의 예시 문장 만들어주세요\n",
        "input_text = \"[CLS] AI가 분석한 결과, 김민지, 김윤서, 김일호, 김재성, 김찬우, 김현서, 노승혁, 류한결, 문건우, 문선아, 엄태림, 윤해민, 이종현, 이지현, 황종빈 이렇게 총 15 명의 INSGIHT의 13기 학회원 중 차기 회장은 [MASK]이다.[SEP]\" # 자유롭게 예시 문장 만들어보세요!\n",
        "filled_text = fill_mask(input_text)\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "??? 뭔가요 이거"
      ],
      "metadata": {
        "id": "sXwfBj2aefxc"
      },
      "id": "sXwfBj2aefxc"
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"[CLS] AI가 분석한 결과, 민지, 윤서, 일호, 재성, 찬우, 현서, 승혁, 한결, 건우, 선아, 태림, 해민, 종현, 지현, 종빈 이렇게 총 15 명의 INSGIHT의 13기 학회원 중 차기 회장에 가장 적합한 사람은 [MASK]이다.[SEP]\" # 자유롭게 예시 문장 만들어보세요!\n",
        "filled_text = fill_mask(input_text)\n",
        "print(\"Filled sentence:\", filled_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAOMrYkgekEg",
        "outputId": "8ed14a0f-4ca8-42d3-a196-8dd4f21d8585"
      },
      "id": "KAOMrYkgekEg",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled sentence: AI가 분석한 결과 , 민지 , 윤서 , 일호 , 재성 , 찬우 , 현서 , 승혁 , 한결 , 건우 , 선아 , 태림 , 해민 , 종현 , 지현 , 종빈 이렇게 총 15 명의 INSGIHT의 13기 학회원 중 차기 회장에 가장 적합한 사람은 지현 이다 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 한국어 금융 뉴스 긍정, 부정 분류"
      ],
      "metadata": {
        "id": "w6tXBQQQUUNZ"
      },
      "id": "w6tXBQQQUUNZ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VNl9yVA-UjdC",
        "outputId": "bc695247-2f12-4c52-8f97-adc429467bfa"
      },
      "id": "VNl9yVA-UjdC",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finance_data.csv를 다운로드 합니다"
      ],
      "metadata": {
        "id": "MbRYkRmUcYKa"
      },
      "id": "MbRYkRmUcYKa"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecjZ0-WMUnIT",
        "outputId": "01c3575a-2712-4e34-b4af-8243f9a20a9d"
      },
      "id": "ecjZ0-WMUnIT",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-27 06:32:34--  https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1319001 (1.3M) [text/plain]\n",
            "Saving to: ‘finance_data.csv.2’\n",
            "\n",
            "finance_data.csv.2  100%[===================>]   1.26M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-05-27 06:32:34 (193 MB/s) - ‘finance_data.csv.2’ saved [1319001/1319001]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('finance_data.csv')"
      ],
      "metadata": {
        "id": "EQHuMwZQUpai"
      },
      "id": "EQHuMwZQUpai",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6ZMYHBd5Urli",
        "outputId": "5a5b25fe-06dd-4b01-c417-74038fdade4f"
      },
      "id": "6ZMYHBd5Urli",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     labels                                           sentence  \\\n",
              "0   neutral  According to Gran, the company has no plans to...   \n",
              "1   neutral  Technopolis plans to develop in stages an area...   \n",
              "2  negative  The international electronic industry company ...   \n",
              "3  positive  With the new production plant the company woul...   \n",
              "4  positive  According to the company's updated strategy fo...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b27946d5-a5d8-4553-8f14-2f955f18f47d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b27946d5-a5d8-4553-8f14-2f955f18f47d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b27946d5-a5d8-4553-8f14-2f955f18f47d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b27946d5-a5d8-4553-8f14-2f955f18f47d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-da97ccdd-6157-4fa9-9fff-13e6d878dc73\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da97ccdd-6157-4fa9-9fff-13e6d878dc73')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-da97ccdd-6157-4fa9-9fff-13e6d878dc73 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4846,\n  \"fields\": [\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4838,\n        \"samples\": [\n          \"The Company serves approximately 3,000 customers in over 100 countries.\",\n          \"On Dec. 1, Grimaldi acquired 1.5 million shares and a 50.1-percent stake in Finnlines.\",\n          \"The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kor_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4827,\n        \"samples\": [\n          \"YIT\\uc5d0 \\ub300\\ud55c \\uace0\\uac1d\\ub4e4\\uc758 \\uc2e0\\ub8b0 \\uc99d\\uac00\\ub294 \\uc544\\ud30c\\ud2b8 \\ub9e4\\ub9e4\\uac00 \\uac00\\uc18d\\ud654\\ub41c \\uac83\\uc73c\\ub85c \\ubcfc \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uc0dd\\uc0b0\\uc740 2010\\ub144 \\ub3d9\\uc548 \\uba55\\uc2dc\\ucf54\\uc640 \\ud5dd\\uac00\\ub9ac\\ub97c \\ud3ec\\ud568\\ud55c \\uc5d8\\ucf54\\ud14d\\uc758 \\ub2e4\\ub978 \\uc9c0\\uc5ed\\uc73c\\ub85c \\ud655\\ub300\\ub420 \\uac83\\uc774\\ub2e4.\",\n          \"\\ubc14\\uc774\\uc0b4\\ub77c\\ub294 \\ub610\\ud55c 2009\\ub144\\uc758 2\\uc5b55220\\ub9cc \\uc720\\ub85c\\uc5d0 \\ube44\\ud574 2010\\ub144\\uc5d0\\ub294 2\\uc5b55320\\ub9cc \\uc720\\ub85c\\uac00 \\uc21c\\ub9e4\\ucd9c\\ub420 \\uac83\\uc73c\\ub85c \\uc608\\uc0c1\\ud55c\\ub2e4\\uace0 \\ubc1d\\ud614\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플의 개수 :', len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG1Al8N7Usnj",
        "outputId": "b7970aa4-4216-4449-dcf6-a9b5c6f34b77"
      },
      "id": "zG1Al8N7Usnj",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 개수 : 4846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "neutral, positive. negative를 숫자로 바꿔줍니다. <br>\n",
        "neutral:0, positive:1, negative:2로 바꿀게요"
      ],
      "metadata": {
        "id": "KnjUNsEOdJzG"
      },
      "id": "KnjUNsEOdJzG"
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "fC-xK-nDUuTy",
        "outputId": "cd286670-7cfd-4ad0-8160-bc9fed99aa04"
      },
      "id": "fC-xK-nDUuTy",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-100-910beaa298a3>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   labels                                           sentence  \\\n",
              "0       0  According to Gran, the company has no plans to...   \n",
              "1       0  Technopolis plans to develop in stages an area...   \n",
              "2       2  The international electronic industry company ...   \n",
              "3       1  With the new production plant the company woul...   \n",
              "4       1  According to the company's updated strategy fo...   \n",
              "\n",
              "                                        kor_sentence  \n",
              "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
              "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
              "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
              "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
              "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2f7b2fa-e806-4988-881f-1aa913291d58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>kor_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>According to Gran, the company has no plans to...</td>\n",
              "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>According to the company's updated strategy fo...</td>\n",
              "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2f7b2fa-e806-4988-881f-1aa913291d58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2f7b2fa-e806-4988-881f-1aa913291d58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2f7b2fa-e806-4988-881f-1aa913291d58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5c1cd762-cad2-4cc8-a6ef-07408e9eb226\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c1cd762-cad2-4cc8-a6ef-07408e9eb226')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5c1cd762-cad2-4cc8-a6ef-07408e9eb226 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4846,\n  \"fields\": [\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4838,\n        \"samples\": [\n          \"The Company serves approximately 3,000 customers in over 100 countries.\",\n          \"On Dec. 1, Grimaldi acquired 1.5 million shares and a 50.1-percent stake in Finnlines.\",\n          \"The extracted filtrates are very high in clarity while the dried filter cakes meet required transport moisture limits (TMLs)for their ore grades.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kor_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4827,\n        \"samples\": [\n          \"YIT\\uc5d0 \\ub300\\ud55c \\uace0\\uac1d\\ub4e4\\uc758 \\uc2e0\\ub8b0 \\uc99d\\uac00\\ub294 \\uc544\\ud30c\\ud2b8 \\ub9e4\\ub9e4\\uac00 \\uac00\\uc18d\\ud654\\ub41c \\uac83\\uc73c\\ub85c \\ubcfc \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uc0dd\\uc0b0\\uc740 2010\\ub144 \\ub3d9\\uc548 \\uba55\\uc2dc\\ucf54\\uc640 \\ud5dd\\uac00\\ub9ac\\ub97c \\ud3ec\\ud568\\ud55c \\uc5d8\\ucf54\\ud14d\\uc758 \\ub2e4\\ub978 \\uc9c0\\uc5ed\\uc73c\\ub85c \\ud655\\ub300\\ub420 \\uac83\\uc774\\ub2e4.\",\n          \"\\ubc14\\uc774\\uc0b4\\ub77c\\ub294 \\ub610\\ud55c 2009\\ub144\\uc758 2\\uc5b55220\\ub9cc \\uc720\\ub85c\\uc5d0 \\ube44\\ud574 2010\\ub144\\uc5d0\\ub294 2\\uc5b55320\\ub9cc \\uc720\\ub85c\\uac00 \\uc21c\\ub9e4\\ucd9c\\ub420 \\uac83\\uc73c\\ub85c \\uc608\\uc0c1\\ud55c\\ub2e4\\uace0 \\ubc1d\\ud614\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 dataframe을 dataset 객체로 변환해줍니다"
      ],
      "metadata": {
        "id": "UFpwMzt7dbOf"
      },
      "id": "UFpwMzt7dbOf"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "all_data = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "9EtcjYQ9U24T"
      },
      "id": "9EtcjYQ9U24T",
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndnRYYyxVG3F",
        "outputId": "4f5549a3-317d-45e8-db96-7fe88cc72441"
      },
      "id": "ndnRYYyxVG3F",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 4846\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all_data를 train과 test로 나눠줍니다<br>\n",
        "train : test = 4 : 1로 나눠줍니다"
      ],
      "metadata": {
        "id": "XtUTOhy-df74"
      },
      "id": "XtUTOhy-df74"
    },
    {
      "cell_type": "code",
      "source": [
        "cs = all_data.train_test_split(test_size=0.2)\n",
        "\n",
        "train_cs = cs['train']\n",
        "test_cs = cs['test']"
      ],
      "metadata": {
        "id": "Oauj0GccVJNt"
      },
      "id": "Oauj0GccVJNt",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI-P3-anVlgQ",
        "outputId": "34e82b0e-d0bf-4b37-c988-7c4372a93005"
      },
      "id": "WI-P3-anVlgQ",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 3876\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLum1NfiVmtf",
        "outputId": "0317c0d4-5408-4dd1-c366-c9282ac2588b"
      },
      "id": "tLum1NfiVmtf",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'sentence', 'kor_sentence'],\n",
              "    num_rows: 970\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----train_cs-----\")\n",
        "print(train_cs)\n",
        "print(\"-----test_cs-----\")\n",
        "print(test_cs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwLbKD21VtsZ",
        "outputId": "4dcd0a61-7093-4598-be31-550b4fab5445"
      },
      "id": "UwLbKD21VtsZ",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----train_cs-----\n",
            "Dataset({\n",
            "    features: ['labels', 'sentence', 'kor_sentence'],\n",
            "    num_rows: 3876\n",
            "})\n",
            "-----test_cs-----\n",
            "Dataset({\n",
            "    features: ['labels', 'sentence', 'kor_sentence'],\n",
            "    num_rows: 970\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 샘플과, 샘플에 해당하는 레이블을 출력합니다.<br>\n",
        "레이블은 0: neutral, 1: positive, 2: negative였죠"
      ],
      "metadata": {
        "id": "Gs-zl-yheGsy"
      },
      "id": "Gs-zl-yheGsy"
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플:', train_cs['kor_sentence'][0])\n",
        "print('샘플의 레이블:', train_cs['labels'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE5NJBnCWA1R",
        "outputId": "f85357ba-05d4-489f-87f7-ade3eae7fae7"
      },
      "id": "SE5NJBnCWA1R",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플: 엘리사는 \"3세대 모바일 기술을 채택한 고객들 덕분에 2007년 한 해 동안 모바일 가입이 7% 증가했다\"고 말했다.\n",
            "샘플의 레이블: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss"
      ],
      "metadata": {
        "id": "ZaKsc7NEWDN6"
      },
      "id": "ZaKsc7NEWDN6",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 `[CLS] 문장 [SEP]` 구조를 만듭니다.\n"
      ],
      "metadata": {
        "id": "_B8aU2LzeSit"
      },
      "id": "_B8aU2LzeSit"
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train_cs['kor_sentence']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test_cs['kor_sentence']))"
      ],
      "metadata": {
        "id": "PzNtwi-IXUoR"
      },
      "id": "PzNtwi-IXUoR",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, validation, test에 대해 labels 정보만 따로 저장합니다"
      ],
      "metadata": {
        "id": "UBw9FB0MeV80"
      },
      "id": "UBw9FB0MeV80"
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_cs['labels']\n",
        "test_labels = test_cs['labels']"
      ],
      "metadata": {
        "id": "XcvXe3M1XVvR"
      },
      "id": "XcvXe3M1XVvR",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test_sentences와 test_labels를 확인합니다"
      ],
      "metadata": {
        "id": "bnTxuaXDeael"
      },
      "id": "bnTxuaXDeael"
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKnDY47YXXD5",
        "outputId": "123860d1-8963-452e-917c-50f1d51e5065"
      },
      "id": "TKnDY47YXXD5",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 거래는 내년 봄에 완료될 것으로 예상된다. [SEP]',\n",
              " '[CLS] 이들 중 73명은 원더웨어 시스템 플랫폼과 같은 최신 ArchistrA 기술을 기반으로 한 제품에 대한 보다 광범위한 교육도 받고 있다. [SEP]',\n",
              " '[CLS] 유타의 수도는 스키 장비 회사인 아머 스포츠사의 다음 미국 본사가 되기를 원했다. [SEP]',\n",
              " '[CLS] 회사 측은 휴대폰 충전기 시장의 치열한 경쟁에 부응하기 위해 영업 효율화 조사에 착수했다고 밝혔다. [SEP]',\n",
              " '[CLS] 에콰도르 이노바르-UIO의 엠프레사 데 데사롤로 우르바노 데 키토는 포이리에게 새로운 도시형 대중 교통 시스템을 위한 타당성 조사를 준비하라고 의뢰했다. [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCd1t7anXYcI",
        "outputId": "bb4ac949-d881-4229-e446-ae110f703dd4"
      },
      "id": "fCd1t7anXYcI",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer와 model을 불러옵니다.<br>\n",
        "tokenizer로는 BertTokenizer를 사용하고, model은 분류모델인 BertForSequenceClassification을 사용합니다<br>\n",
        "우리는 neutral, negative, positive중에 하나를 예측해야 하므로, num_labels에 3을 넣어서 model에 num_labels를 넘겨줍니다"
      ],
      "metadata": {
        "id": "O-DF8jY-ec7t"
      },
      "id": "O-DF8jY-ec7t"
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 BERT 중 하나인 'klue/bert-base'를 사용.\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base') # 사전학습 된 상태로 불러옵니다\n",
        "\n",
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels) # 사전학습 된 상태로 불러옵니다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vfBq29yXagY",
        "outputId": "6a653a81-d827-4815-ea78-dc03c4ba6472"
      },
      "id": "0vfBq29yXagY",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래 BERT는 max_length가 512지만, 128로 축소해서 학습하면 더 빠른 시간에 학습이 가능합니다.\n",
        "# MAX_LEN을 128로 하고, 성능이 좋지 않으면 MAX_LEN을 256 -> 384 -> 512로 늘려가며 비교하는 것도 방법입니다\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 실습때 했던 encode_korquad_examples() 함수 기억하시나요? 그 함수와 유사하게 작성되었습니다.\n",
        "def encode_classification_data(sentences, labels):\n",
        "    encodings = tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encodings['input_ids']\n",
        "    attention_mask = encodings['attention_mask']\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "xADUO_97Xb6h"
      },
      "id": "xADUO_97Xb6h",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, validation, test 데이터셋을 생성합니다"
      ],
      "metadata": {
        "id": "3eTT7qU4fX1B"
      },
      "id": "3eTT7qU4fX1B"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = encode_classification_data(train_sentences, train_labels)\n",
        "test_dataset = encode_classification_data(test_sentences, test_labels)"
      ],
      "metadata": {
        "id": "J_o3v1GaXeEY"
      },
      "id": "J_o3v1GaXeEY",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터의 크기:', len(train_dataset))\n",
        "print('테스트 데이터의 크기:', len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3XCY79hX8lz",
        "outputId": "837101c4-3531-4f6d-cee3-63ddc0285915"
      },
      "id": "n3XCY79hX8lz",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기: 3876\n",
            "테스트 데이터의 크기: 970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader를 생성합니다"
      ],
      "metadata": {
        "id": "iwWu8eunfd3C"
      },
      "id": "iwWu8eunfd3C"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=RandomSampler(train_dataset),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=SequentialSampler(test_dataset),  # 테스트도 일반적으로 Sequential을 씀\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "p1lKV4xDYMHE"
      },
      "id": "p1lKV4xDYMHE",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 지정\n",
        "# AdamW 사용합니다\n",
        "# AdamW에 모델의 파라미터 정보를 넘겨줍니다.\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps = 1e-8)"
      ],
      "metadata": {
        "id": "evpOx_OKYFDs"
      },
      "id": "evpOx_OKYFDs",
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 학습합니다"
      ],
      "metadata": {
        "id": "ExHpHot8f9-z"
      },
      "id": "ExHpHot8f9-z"
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # gpu 사용 가능하면 gpu(cuda)로, 그렇지 않으면 cpu로\n",
        "model.to(device)\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train() # 모델을 학습 모드로 설정합니다\n",
        "\n",
        "    loop = tqdm(train_dataloader, desc=f'Epoch {epoch_i + 1}', leave=False)\n",
        "\n",
        "    for step, batch in enumerate(loop):\n",
        "        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "        optimizer.zero_grad() # 가중치 0으로 초기화\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward() # 역전파\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step() # 파라미터 업데이트\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(f\"\\n  Average training loss: {avg_train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqMeGbE3ZFnJ",
        "outputId": "2fcc9b77-91e7-430f-f0eb-fd05b1a1c414"
      },
      "id": "FqMeGbE3ZFnJ",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.4948\n",
            "\n",
            "======== Epoch 2 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 0.2729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 모델의 가중치를 저장합니다"
      ],
      "metadata": {
        "id": "r0iyJ85EgmYH"
      },
      "id": "r0iyJ85EgmYH"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"BERT_news.pt\")"
      ],
      "metadata": {
        "id": "7qBYAElLZwUU"
      },
      "id": "7qBYAElLZwUU",
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 가중치를 다시 불러옵니다<br>\n",
        "- 지금처럼 학습과 테스트를 한 번에 이어서 할 때는 모델 가중치를 다시 불러올 필요가 없습니다.\n",
        "- 그러나 내가 이전에 학습한 모델을 사용해서 예측을 수행하고 싶을 때는 다음과 같이 이전에 학습된 가중치를 불러와야 합니다"
      ],
      "metadata": {
        "id": "j4efz5digorv"
      },
      "id": "j4efz5digorv"
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels)\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "model.load_state_dict(torch.load(\"BERT_news.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_yPgKZMazGi",
        "outputId": "df065736-5d36-46fd-c061-c6e5b2324cb1"
      },
      "id": "n_yPgKZMazGi",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가하기 위한 함수를 정의합니다"
      ],
      "metadata": {
        "id": "xxZpNjrQf8D8"
      },
      "id": "xxZpNjrQf8D8"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(preds, labels):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'f1_macro': f1_score(labels, preds, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(labels, preds, average='micro', zero_division=0),\n",
        "        'f1_weighted': f1_score(labels, preds, average='weighted', zero_division=0)\n",
        "    }"
      ],
      "metadata": {
        "id": "oafGGaIEflTT"
      },
      "id": "oafGGaIEflTT",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터에 대해 평가를 수행합니다"
      ],
      "metadata": {
        "id": "TlpErKvug2Zo"
      },
      "id": "TlpErKvug2Zo"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            token_type_ids=None\n",
        "        )\n",
        "\n",
        "    logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 예측 결과 저장\n",
        "    accum_logits.extend(np.argmax(logits, axis=1))\n",
        "    accum_label_ids.extend(label_ids)\n",
        "\n",
        "# NumPy 배열로 변환\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "\n",
        "# 메트릭 계산\n",
        "results = compute_metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "# 출력\n",
        "print(\"\\n[✔️ Test Evaluation Result]\")\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS5RSE5DaBEF",
        "outputId": "4abb8687-026d-4051-ec62-5777ae513c20"
      },
      "id": "aS5RSE5DaBEF",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 61/61 [00:07<00:00,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[✔️ Test Evaluation Result]\n",
            "Accuracy: 0.8536\n",
            "F1 (Macro) Score: 0.8360\n",
            "F1 (Micro) Score: 0.8536\n",
            "F1 (Weighted) Score: 0.8528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HuggingFace transformers 라이브러리의 pipeline API를 활용하면 텍스트 분류 모델을 추론하기 위한 설정을 편리하게 할 수 있습니다"
      ],
      "metadata": {
        "id": "rxoXjbl0g4zA"
      },
      "id": "rxoXjbl0g4zA"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipe = pipeline(\"text-classification\", # 수행할 작업: 텍스트 분류\n",
        "                model=model.to(device), # 사용할 모델\n",
        "                tokenizer=tokenizer, # 모델에 맞는 토크나이저\n",
        "                max_length=512, # 입력 문장 최대 길이\n",
        "                return_all_scores=True, # 모든 클래스의 확률 반환\n",
        "                function_to_apply='softmax' # softmax 사용\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cenQIx_JZxe1",
        "outputId": "e2d01eb9-e99e-471b-9d3c-4a7336d8d551"
      },
      "id": "cenQIx_JZxe1",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('SK하이닉스가 매출이 급성장하였다') # 이 문장에 대해 label 점수를 보면\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_KLJZK_bN9t",
        "outputId": "d89b8c51-0bb3-45b5-9a81-915e2030cf45"
      },
      "id": "c_KLJZK_bN9t",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'LABEL_0', 'score': 0.12372135370969772}, {'label': 'LABEL_1', 'score': 0.863305926322937}, {'label': 'LABEL_2', 'score': 0.012972715310752392}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_all_scores = True로 했기 때문에 LABEL_0, LABEL_1, LABEL_2의 모든 score가 다 출력됩니다"
      ],
      "metadata": {
        "id": "VZm_pLmliBOW"
      },
      "id": "VZm_pLmliBOW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL_0, LABEL_1, LABEL_2 대신에 중립, 긍정, 부정으로 출력하도록 label_dict를 설정합니다"
      ],
      "metadata": {
        "id": "lDxA2TsniGbA"
      },
      "id": "lDxA2TsniGbA"
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}"
      ],
      "metadata": {
        "id": "ms8u3r6TbCRk"
      },
      "id": "ms8u3r6TbCRk",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "label_dict에서 LABEL_0, LABEL_1, LABEL_2를 중립, 긍정, 부정으로 바꿔서 출력하는 함수를 정의합니다"
      ],
      "metadata": {
        "id": "sZ5sItmTiSIh"
      },
      "id": "sZ5sItmTiSIh"
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(text):\n",
        "  result = pipe(text)\n",
        "\n",
        "  return [label_dict[result[0]['label']]]"
      ],
      "metadata": {
        "id": "sFdQKVVLbEG7"
      },
      "id": "sFdQKVVLbEG7",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전의 pileline 코드에서 return_all_scores를 제거합니다. return_all_scores는 default가 False입니다\n",
        "pipe = pipeline(\"text-classification\", model=model.to(device), tokenizer=tokenizer, max_length=512,function_to_apply='softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZQ9u9jibfwW",
        "outputId": "497a7e17-27f1-44f3-971c-edca61d895ec"
      },
      "id": "8ZQ9u9jibfwW",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MoC1FFDbii-",
        "outputId": "320ec8c6-79f5-4e8b-a7a7-0764b3a91db0"
      },
      "id": "1MoC1FFDbii-",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_1', 'score': 0.863305926322937}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_all_scores를 False로 했으므로 가장 높은 score의 LABEL만 출력됩니다"
      ],
      "metadata": {
        "id": "hrs7W6Rqic9R"
      },
      "id": "hrs7W6Rqic9R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction 함수를 사용하여 다양한 금융 텍스트의 긍정/부정/중립을 분석해보면"
      ],
      "metadata": {
        "id": "SFTC9xoMiruT"
      },
      "id": "SFTC9xoMiruT"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('SK하이닉스가 매출이 급성장하였다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPs7syKa69T",
        "outputId": "2c2b945a-8f27-4eff-9482-4fd63aa83163"
      },
      "id": "UhPs7syKa69T",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['긍정']"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('ChatGPT의 등장으로 인공지능 스타트업들은 비상이다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPmPUwUeblDG",
        "outputId": "cdd3538c-6004-4013-e942-ddebf653ea5f"
      },
      "id": "kPmPUwUeblDG",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['중립']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('인공지능 기술의 발전으로 누군가는 기회를 얻을 것이고, 누군가는 얻지 못할 것이다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6QE8Ki_bmS3",
        "outputId": "aca5eaf4-e132-42dd-b7cf-ab51e415cbce"
      },
      "id": "f6QE8Ki_bmS3",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['중립']"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('삼성전자의 주가가 상승곡선을 그리고 있다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiGbXQYIbm2O",
        "outputId": "b2dcde00-5981-42e5-a607-69e8dfc398f3"
      },
      "id": "RiGbXQYIbm2O",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['긍정']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zqfEZ0wkPsLA",
      "metadata": {
        "id": "zqfEZ0wkPsLA"
      },
      "source": [
        "# 2. Text Generation : GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "_VV4vozKQM4C",
      "metadata": {
        "id": "_VV4vozKQM4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34beed54-3d88-42d5-898b-5108568b803e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "금융 경제분야, 수화 번역, 추천 시스템 분석, 패션 플랫폼 리뷰 nlp, 날씨 예측 공모전, 방송통신위원회 데이터 분석 공모전이라는 다양한 주제로 진행되는 이번 2차 인사이콘에서 어떤 팀이 우승할까?라는 질문에 대해 “1차 예선에서 탈락한 팀들이 다시 도전해보고 싶다”며 “이번에도 좋은 결과가 있을 것으로 기대한다”고 말했다.\n",
            "이날 1차 합격자 발표는 오는 24일 오후 6시 30분부터 진행되며, 최종 결과는 26일 오전 10시에 발표된다.</d> 한국토지주택공사(LH)는 지난달 말 기준 전국 미분양 주택은 총 1만2천911가구로 전월(1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "# 시작 텍스트 설정\n",
        "# 예시 text = '인사이트 13기 회장, 부회장은 과연 누가 될까? 너무 기대된다'\n",
        "# 예시 텍스트 말고 다른 text 직접 입력해보세요! 기발한 아이디어 기다립니다ㅎㅎ\n",
        "text = '금융 경제분야, 수화 번역, 추천 시스템 분석, 패션 플랫폼 리뷰 nlp, 날씨 예측 공모전, 방송통신위원회 데이터 분석 공모전이라는 다양한 주제로 진행되는 이번 2차 인사이콘에서 어떤 팀이 우승할까?'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "\n",
        "# 텍스트 생성\n",
        "gen_ids = model.generate(input_ids,\n",
        "                         max_length=128,\n",
        "                         repetition_penalty=2.0,\n",
        "                         pad_token_id=tokenizer.pad_token_id,\n",
        "                         early_stopping=True,\n",
        "                         eos_token_id=tokenizer.eos_token_id,\n",
        "                         bos_token_id=tokenizer.bos_token_id,\n",
        "                         use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![스크린샷 2025-05-25 181321.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "UKNpok8MucIw"
      },
      "id": "UKNpok8MucIw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㅋㅋㅋㅋ 회장, 부회장의 단어를 보고 인사이트를 기업으로 인식한 거 같아요"
      ],
      "metadata": {
        "id": "TBrGpnyIT1NH"
      },
      "id": "TBrGpnyIT1NH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "과제 끝!!"
      ],
      "metadata": {
        "id": "Zf7ovu23T0Q2"
      },
      "id": "Zf7ovu23T0Q2"
    },
    {
      "cell_type": "markdown",
      "id": "v3BcoUr_GTnJ",
      "metadata": {
        "id": "v3BcoUr_GTnJ"
      },
      "source": [
        "# 3. Langchain ~ Rag (참고)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y7dig7dRIkF8",
      "metadata": {
        "id": "Y7dig7dRIkF8"
      },
      "source": [
        "### Langchain\n",
        "- LLM을 사용한 어플리케이션 개발 단순화를 위한 프레임워크\n",
        "- python과 JavaScript 라이브러리 제공\n",
        "- 요약, 번역, 챗봇, QnA, 데이터 증강(Augmentation) 등의 서비스 구현 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7pc9jY4dJYGO",
      "metadata": {
        "id": "7pc9jY4dJYGO"
      },
      "source": [
        "### RAG\n",
        "- LLM 모델의 단점 중 사실 관계 오류 가능성과 맥락 이해의 한계를 개선하는데 초점을 맞춘 방법\n",
        "- 외부 지식 베이스를 연결해 모델의 생성 능력과 사실 관계 파악 능력 향상\n",
        "- 할루시네이션 감소와 최신 정보 반영에 유리"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드 실행하려면 OPEN AI의 langchain API Key가 필요한데, 현재는 유료라서... 그냥 실행하지 말고 보기만 해주세요"
      ],
      "metadata": {
        "id": "gtwJGlpKToym"
      },
      "id": "gtwJGlpKToym"
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "G3lzSLe4GUUX",
      "metadata": {
        "id": "G3lzSLe4GUUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7af9d7-dde2-49b9-be7b-a8921839b099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.0.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.35.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured) (2025.4.26)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (2.11.4)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.35.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=b499e4861f236974b4829ff7adabb838e92e2f1f3ff7e640c244c7fbfbb692c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, mypy-extensions, marshmallow, langdetect, emoji, backoff, aiofiles, typing-inspect, python-oxmsg, unstructured-client, dataclasses-json, unstructured\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 dataclasses-json-0.6.7 emoji-2.14.1 filetype-1.2.0 langdetect-1.0.9 marshmallow-3.26.1 mypy-extensions-1.1.0 olefile-0.47 pypdf-5.5.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 typing-inspect-0.9.0 unstructured-0.17.2 unstructured-client-0.35.0\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m544.2/664.8 MB\u001b[0m \u001b[31m158.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m'import warnings' failed; traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 570, in <module>\n",
            "    _processoptions(sys.warnoptions)\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 209, in _processoptions\n",
            "    _setoption(arg)\n",
            "  File \"/usr/lib/python3.11/warnings.py\", line 225, in _setoption\n",
            "    import re\n",
            "  File \"/usr/lib/python3.11/re/__init__.py\", line 251, in <module>\n",
            "    _special_chars_map = {i: '\\\\' + chr(i) for i in b'()[]{}?*+-|^$\\\\.&~# \\t\\n\\r\\v\\f'}\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/re/__init__.py\", line 251, in <dictcomp>\n",
            "    _special_chars_map = {i: '\\\\' + chr(i) for i in b'()[]{}?*+-|^$\\\\.&~# \\t\\n\\r\\v\\f'}\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install unstructured\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WqF4ImUyHazE",
      "metadata": {
        "id": "WqF4ImUyHazE"
      },
      "source": [
        "## 1. 데이터 가져오기\n",
        "- 분석할 문서를 불러와 데이터 파이프라인의 입력으로 사용\n",
        "- 자연어 처리를 수행하기 위해 원천 데이터를 준비하는 단계\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "VwuthDp5GaZB",
      "metadata": {
        "id": "VwuthDp5GaZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "619bb2e0-9f9f-4bd5-b4ee-d90e2573d08b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Module langchain_community.document_loaders not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-5fec49d0e1b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AI.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/document_loaders/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;34m\"\"\"Look up attributes dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_community\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;34mf\"Module {new_module} not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34m\"Please install langchain-community to access this module. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Module langchain_community.document_loaders not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "documents = TextLoader(\"AI.txt\").load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ICqSGfl2HjgE",
      "metadata": {
        "id": "ICqSGfl2HjgE"
      },
      "source": [
        "## 2. 텍스트 분할\n",
        "- 긴 문서를 일정 크기의 청크로 나눠 처리 가능하도록 만듦\n",
        "- 검색 효율성과 모델의 입력 제약을 고려한 전처리 작업\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qx5bjqBxGcDU",
      "metadata": {
        "id": "qx5bjqBxGcDU"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 문서를 청크로 분할\n",
        "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "# docs 변수에 분할 문서를 저장\n",
        "docs = split_docs(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7v-0gnNJHn_M",
      "metadata": {
        "id": "7v-0gnNJHn_M"
      },
      "source": [
        "## 3. 임베딩 변환\n",
        "- 텍스트 데이터를 벡터 공간으로 매핑하여 기계 학습 모델이 이해할 수 있는 수치 데이터로 변환\n",
        "- 텍스트의 의미적 유사성을 계산하고 처리를 자동화하기 위한 단계\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3rtyWeKHGfwc",
      "metadata": {
        "id": "3rtyWeKHGfwc"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RA02sWNfIFsI",
      "metadata": {
        "id": "RA02sWNfIFsI"
      },
      "source": [
        "## 4. 벡터 저장\n",
        "- 변환된 벡터 데이터를 데이터베이스에 저장하여 고속 검색과 활용 지원\n",
        "- 효율적인 질의 응답 및 문서 검색 시스템 구현을 위한 핵심 단계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cV0ab-ryIDKw",
      "metadata": {
        "id": "cV0ab-ryIDKw"
      },
      "outputs": [],
      "source": [
        "# Chromdb에 벡터 저장\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4wZXuxWKHp7Y",
      "metadata": {
        "id": "4wZXuxWKHp7Y"
      },
      "source": [
        "## 5. 질문 응답\n",
        "- 입력된 질문과 관련된 문서를 검색한 뒤 GPT 모델로 답변 생성\n",
        "- 사용자 질문에 적합한 답변을 제공하기 위해 유사 문서 검색과 자연어 처리를 결합한 핵심 과정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JLg25a9sGhnC",
      "metadata": {
        "id": "JLg25a9sGhnC"
      },
      "outputs": [],
      "source": [
        "import os #운영체제(os) 모듈을 가져올 때 사용되는 라이브러리\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\" #openai 키 입력 -> 현재 유료로 사용 가능,,,ㅠㅠ\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "model_name = \"gpt-3.5-turbo\"  #GPT-3.5 turbo 모델 사용\n",
        "llm = ChatOpenAI(model_name=model_name)\n",
        "\n",
        "# Q&A 체인을 사용하여 쿼리에 대한 답변 얻기\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\",verbose=True)\n",
        "\n",
        "# 쿼리를 작성하고 유사성 검색을 수행하여 답변을 생성,따라서 txt에 있는 내용을 질의해야 합니다\n",
        "query = \"AI란?\"\n",
        "matching_docs = db.similarity_search(query)\n",
        "answer =  chain.run(input_documents=matching_docs, question=query)\n",
        "answer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "721.212px",
        "left": "71px",
        "top": "87.7936px",
        "width": "302.538px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}